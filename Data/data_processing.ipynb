{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Libraries imports"
      ],
      "metadata": {
        "id": "gUFXIL2JR6JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#plt.rc('figure',figsize=(17,13))\n",
        "#import plotly.express as px\n",
        "#import plotly.graph_objs as go\n",
        "#import plotly.offline as pyo\n",
        "#from plotly.subplots import make_subplots\n",
        "#pyo.init_notebook_mode()\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk import pos_tag\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "1nvLt1Jp5O7F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9418e8a-bacc-4939-b696-1933f3dfd752"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.10/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Data import"
      ],
      "metadata": {
        "id": "zjC0pRfGSCLv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqabg7GClHet",
        "outputId": "caf9db7e-9899-4df7-b20c-261dd703fd1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# If you want to import the csv dataset file without using Google Drive, you can ignore this cell\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/My Drive/data_group_2.csv' # This path must be replaced. The data that has to be imported here is the tweets.csv file given in the Kaggle.\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "iHs6l5C3mB7Z"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Data cleaning and processing"
      ],
      "metadata": {
        "id": "LprTSFuiSLQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text']=df['text'].astype(str)\n",
        "df['text']=[x.replace(':',' ') for x in df['text']]"
      ],
      "metadata": {
        "id": "2n19MvITqxvl"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser=SentimentIntensityAnalyzer()\n",
        "scores=[]\n",
        "for i in range(len(df['text'])):\n",
        "    score=analyser.polarity_scores(df['text'][i])\n",
        "    score=score['compound']\n",
        "    scores.append(score)\n",
        "sentiment=[]\n",
        "for i in scores:\n",
        "    if i>=0.05:\n",
        "        sentiment.append('Positive')\n",
        "    elif i<=(-0.05):\n",
        "        sentiment.append('Negative')\n",
        "    else:\n",
        "        sentiment.append('Neutral')\n",
        "df['sentiment']=pd.Series(np.array(sentiment))"
      ],
      "metadata": {
        "id": "31xdKqqYpQM7"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['sentiment'] == 'Negative']"
      ],
      "metadata": {
        "id": "fwVipasbr0lm"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "M4GTyywfr5rQ"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['hashtags', 'source', 'user_name', 'sentiment', 'user_friends', 'user_verified'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "xXwniGhd_HVc"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eBmlMWE43Sp",
        "outputId": "810de8f4-51af-4156-fd0b-36d7b66ed444"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26237, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select randomly 200 rows\n",
        "df_sample = df.sample(n=200, random_state=42)"
      ],
      "metadata": {
        "id": "lbcX1PeG-btx"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. The next part consist in couting the number of tokens for the final prompt and for the sample dataset in order to be sure that GPT-turbo-0125 will be able to process our request"
      ],
      "metadata": {
        "id": "9KJ4OFIRQtA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = '''\n",
        "<context>\n",
        "I am analyzing a dataset of tweets about the development of large language models (LLMs) like GPT-4 to identify public concerns.\n",
        "I aim to understand how these concerns are influenced by the tweet's date, the geographical location of the user, their profile, and the tweet's popularity.\n",
        "</context>\n",
        "\n",
        "<persona>\n",
        "Adopt the role of a researcher with a strong background in LLM and more generally on AI.\n",
        "</persona>\n",
        "\n",
        "<research question>\n",
        "What are the primary concerns expressed by the public regarding the development of large language models (LLMs), and how do\n",
        "these concerns correlate with specific factors such as date, geographical location, user profile and popularity ?\n",
        "</research question>\n",
        "\n",
        "<instructions>\n",
        "1. Take the time to do an in-depth analyze of the dataset. Then propose a small summary of the main keypoints that can bring an answer to the research question ? This summary should be 100 words long.\n",
        "2. Analysis of Concerns: Identify recurring themes in the concerns expressed about LLMs in the tweets. Use examples from tweets to illustrate each identified theme.\n",
        "3. Correlation with Date: Examine how themes vary with the date of the tweet's publication. Describe observed trends and their possible significance.\n",
        "4. Influence of Geographical Location: Link specific concerns to particular regions or countries, if possible. Explain how location might influence perceptions of LLMs.\n",
        "5. Impact of User Profile: Analyze whether the user description and the user creation date seem to influence the type of concerns expressed.\n",
        "6. Relationship with Popularity: Discuss the relationship between the tweet's popularity (measured by userâ€™s followers, friends, favourites and if he is verified) and the nature of concerns.\n",
        "    Determine whether more popular tweets reflect concerns that are more widely shared or not.\n",
        "7. According to the results of your analysis, propose 2 hypothesis that explain the findings. This part should include argumentation and explanation.\n",
        "From Part 2 to Part 6, consider each part should be of 200-250 words. This number of words is purely indicative, if a part needs more words it can be longer.\n",
        "\n",
        "Example for part 1 :\n",
        "\"After examining the dataset, primary public concerns about LLMs include data privacy, algorithmic bias, and misuse of technology. Data shows a spike\n",
        "in concerns related to privacy following high-profile data breaches. Geographically, concerns vary with higher anxiety in regions with strict data protection laws. Popular tweets, often\n",
        "from influencers, suggest wider shared concerns, particularly about transparency and the ethical use of AI.\"\n",
        "\n",
        "Example for part 2 :\n",
        "\"Recurring themes in the concerns about LLMs include:\n",
        "â€¢\tData Privacy: Many users express fear about personal data misuse. For example, a tweet from January 2021 states, 'Worried about how GPT-4 might handle my data. #PrivacyMatters.'\n",
        "â€¢\tAlgorithmic Bias: Concerns about bias in AI decisions are common, exemplified by a tweet from March 2022: 'How do we know AI isn't biased? #TechEthics.'\n",
        "â€¢\tMisuse of AI: Fears of AI being used for deceptive purposes, highlighted by a tweet: 'Could LLMs be the next tool for misinformation? #AIResponsibility.'\"\n",
        "\n",
        "Example for part 3 :\n",
        "\"Analysis reveals an uptick in privacy concerns coinciding with news of data breaches or policy changes. For instance, tweets from late 2021 show\n",
        "heightened anxiety when a major tech company faced a data scandal. Themes of ethical use of AI surged around elections or significant political events, suggesting that public awareness\n",
        "is heightened by contextual global events.\"\n",
        "\n",
        "Example for part 4 :\n",
        "\"After reviewing the dataset, there does not appear to be a clear or consistent relationship between the geographical location of the tweet\n",
        "authors and the specific concerns they express about LLMs. For instance, concerns about data privacy are equally prevalent in tweets from users in Europe,\n",
        "Asia, and North America, without significant variation that aligns with local data protection laws. Similarly, worries about algorithmic bias and AI misuse are\n",
        "scattered across diverse locations, suggesting these concerns are globally shared and not particularly influenced by regional factors.\"\n",
        "\n",
        "Example for part 5 :\n",
        "\"Analysis reveals a clear relationship between user profiles and the concerns they express about LLMs. Accounts created during key AI\n",
        "milestones, such as the release of GPT-4, often tweet about advanced AI issues like transparency. For example, an account from 2021: 'How safe are these new AIs?' Furthermore,\n",
        "users with tech-related roles in their descriptions, like 'AI researcher,' frequently discuss ethical implications, shown by a tweet: 'We need stricter AI oversight #AIethics.'\n",
        "These patterns indicate that both account age and professional interests shape the concerns users articulate.\"\n",
        "\n",
        "Example for part 6 :\n",
        "\"Analysis of the tweet data shows no clear correlation between the popularity of tweets (measured by factors such as retweets,\n",
        "likes, and whether the user is verified) and the nature of concerns expressed about LLMs. Both highly popular and less popular tweets vary widely in their focus, with high-engagement\n",
        "posts sometimes addressing general topics about AI, while other, less popular tweets might delve into specific issues like privacy or bias. This indicates that the reach of a tweet does\n",
        "not necessarily reflect a broader or more significant concern among the public.\"\n",
        "\n",
        "Example for part 7 :\n",
        "Hypothesis 1: \"The heightened concern about data privacy correlates strongly with geographical locations that have strict data protection laws, suggesting that regulatory environments\n",
        "significantly influence public sentiment about LLMs.\"\n",
        "Hypothesis 2: \"The prominence of concerns related to ethical AI use among influencers and verified accounts may amplify these issues, leading to increased public awareness and potentially\n",
        " influencing policy discussions. This indicates that public figures play a crucial role in shaping discourse around AI ethics.\"\n",
        "\n",
        "The number of words given are purely indicative. If a part need more text to be relevant it can be longer.\n",
        "</instructions>\n",
        "\n",
        "<format>\n",
        "Minimum 1000 words, markdown syntax\n",
        "</format>\n",
        "'''"
      ],
      "metadata": {
        "id": "EjHTHcOcBnoF"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the sample dataset into a string\n",
        "csv_string = df_sample.to_csv(index=False, sep=',', header=False)"
      ],
      "metadata": {
        "id": "77pNBUaK9X9a"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for counting the number of tokens\n",
        "def count_tokens(text):\n",
        "    nltk.download('punkt')\n",
        "    tokens = word_tokenize(text)\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "l8bJXxuO-O8E"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_data = count_tokens(csv_string)\n",
        "print(\"Number of tokens in the CSV string:\", token_count_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-otobMX3-lPZ",
        "outputId": "9b7e8d8d-0fab-42d4-de40-3ae62fa3952f"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in the CSV string: 12879\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_count_prompt = count_tokens(prompt)\n",
        "print(\"Number of tokens in the final prompt:\", token_count_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDqK9IaGBraV",
        "outputId": "8b040595-f3af-4828-8888-938a08119019"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in the final prompt: 1119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total of tokens :\", token_count_data + token_count_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIGaDhKTClG2",
        "outputId": "40769302-66b7-4250-8f51-46d0b3d1d3fe"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total of tokens : 13998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. The final part of this notebook consist in extracting the dataset into a csv file"
      ],
      "metadata": {
        "id": "OFvSkTgcRqCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.to_csv('sample_data.csv', index=False)"
      ],
      "metadata": {
        "id": "coMqwsm_R2IK"
      },
      "execution_count": 198,
      "outputs": []
    }
  ]
}